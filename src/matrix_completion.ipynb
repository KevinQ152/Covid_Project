{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "import copy\n",
    "\n",
    "# Note: I put lmafit inside src/ to make things easier for right now\n",
    "from lmafit import lmafit_mc_adp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the data\n",
    "cwd = os.getcwd()\n",
    "par = os.path.join(cwd, os.pardir)\n",
    "par = os.path.abspath(par)\n",
    "parpar = os.path.join(par, os.pardir)\n",
    "parpar = os.path.abspath(parpar)\n",
    "nyt_datapath = os.path.join(par, 'UniversityCases', '')\n",
    "big10_datapath = os.path.join(parpar, 'college-covid19-dataset', 'data', '')\n",
    "\n",
    "fnames = sorted(glob.glob(nyt_datapath+'*.csv'))\n",
    "frames = []\n",
    "for f in fnames:\n",
    "    #m = re.search(r'[^0-9]*([0-9][0-9_]+)[^0-9]*', f)\n",
    "    df = pd.read_csv(f)\n",
    "    \n",
    "    #df['Date'] = pd.to_datetime(m.group(1), format='%m_%d_%y')\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%m-%d-%Y')\n",
    "    \n",
    "    df.drop(['Unnamed: 0'], axis = 1, inplace=True)\n",
    "    df['Cases'] = df['Cases'].apply(lambda x: x.replace(',', '')).astype('int')\n",
    "    frames.append(df)\n",
    "    \n",
    "nyt_df = pd.concat(frames)\n",
    "\n",
    "big10_df = pd.read_csv(os.path.join(big10_datapath, 'daily.csv'))\n",
    "old_cols = big10_df.columns.values.copy()\n",
    "old_cols[0] = 'School'\n",
    "big10_df.columns = old_cols\n",
    "big10_df['Date'] = pd.to_datetime(big10_df['Date'],format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_df = nyt_df.sort_values('Date')\n",
    "big10_df = big10_df.sort_values('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_df = nyt_df.drop_duplicates(subset = ['School','Cases'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine NYT and Big 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find list of schools\n",
    "schools = list(pd.unique(nyt_df.School))\n",
    "# NOTE: something I noticed is that some of the schools have less data points than the others. Not sure why.\n",
    "\n",
    "# Create an index with dates between september 8 (start of NYT collection) and today\n",
    "start_day = dt.datetime(2020, 9, 8)\n",
    "indexer = {}\n",
    "c = 0\n",
    "while start_day < dt.datetime.today():\n",
    "    indexer[c] = start_day\n",
    "    start_day = start_day + dt.timedelta(days = 1)\n",
    "    c += 1\n",
    "\n",
    "name_translator = {'University of Illinois Urbana-Champaign':'Illinois',\n",
    "                    'Indiana University Bloomington':'Indiana', \n",
    "                    'University of Iowa':'Iowa',\n",
    "                    'University of Maryland, College Park':'Maryland',\n",
    "                    'Michigan State University':'Michigan State',\n",
    "                    'University of Minnesota Twin Cities':'Minnesota',\n",
    "                    'Northwestern University':'Northwestern',\n",
    "                    'Ohio State University':'Ohio State',\n",
    "                    'Penn State University':'Penn State',\n",
    "                    'University of Wisconsin-Madison':'UW-Madison',\n",
    "                    'University of Michigan':'Michigan',\n",
    "                    'University of Nebraska-Lincoln':'Nebraska', \n",
    "                    'Purdue University':'Purdue',\n",
    "                    'Rutgers University':'Rutgers'}\n",
    "\n",
    "for i in name_translator.keys():\n",
    "    schools.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "strindex = [dt.datetime.strftime(indexer[i], '%Y-%m-%d') for i in indexer]\n",
    "date_index = {indexer[j]:j for j in range(len(indexer))}\n",
    "data_dict = {}\n",
    "\n",
    "# Add all the big 10 schools\n",
    "for i in name_translator.values():\n",
    "    cases = [0 for i in range(len(indexer))]\n",
    "    school = big10_df.loc[big10_df.School == i]\n",
    "    for j in school.Date:\n",
    "        if j >= dt.datetime(2020,9,8):\n",
    "            to_index = date_index[j]\n",
    "            cases[to_index] = school.loc[school.Date == j].Confirmed.iloc[0]\n",
    "        \n",
    "    data_dict[i] = cases\n",
    "\n",
    "\n",
    "# Add all the NYT\n",
    "for i in schools:\n",
    "    cases = [0 for i in range(len(indexer))]\n",
    "    school = nyt_df.loc[nyt_df.School == i]\n",
    "    for j in school.Date:\n",
    "        to_index = date_index[j]\n",
    "        cases[to_index] = school.loc[school.Date == j].Cases.iloc[0]\n",
    "        \n",
    "    data_dict[i] = cases\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop all Zero columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomplete_matr = pd.DataFrame.from_dict(data_dict)\n",
    "no_zero = incomplete_matr.loc[(incomplete_matr!=0).any(axis=1)]\n",
    "dates_used = no_zero.index\n",
    "schools_used = no_zero.columns\n",
    "\n",
    "# Transpose to make things easier\n",
    "arr = no_zero.T.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly hide some of the dates/schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hide_date(matrix, percent):\n",
    "    # returns a copy of the original matrix with x percent of the dates hidden\n",
    "    mat = copy.deepcopy(matrix)\n",
    "    num_hide = int(len(mat[0])*percent)\n",
    "\n",
    "    date_ind = range(len(mat[0]))\n",
    "    to_hide = random.sample(date_ind, num_hide)\n",
    "    to_hide.sort(reverse = True)\n",
    "    \n",
    "    for s in mat:\n",
    "        for t in to_hide:\n",
    "            s.pop(t)\n",
    "    \n",
    "    return mat\n",
    "\n",
    "def hide_school(matrix, percent):\n",
    "    # returns a copy of the original matrix with x percent of the schools hidden\n",
    "    mat = copy.deepcopy(matrix)\n",
    "    num_hide = int(len(mat)*percent)\n",
    "    \n",
    "    school_ind = range(len(mat))\n",
    "    to_hide = random.sample(school_ind, num_hide)\n",
    "    to_hide.sort(reverse = True)\n",
    "    \n",
    "    for t in to_hide:\n",
    "        mat.pop(t)\n",
    "    \n",
    "    return mat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arr = hide_date(arr, 0.5)\n",
    "arr = hide_school(arr, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test if the matrix is row increasing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_inc(matrix, printy=True):\n",
    "    # matrix is a 2d array\n",
    "    # matrix[0] is the first school\n",
    "    # NOTE: That is the transpose of what I'm using elsewhere\n",
    "    #       just to make things easier\n",
    "    \n",
    "    non_inc = {}\n",
    "    for i in range(len(matrix)):\n",
    "        last = matrix[i][0]\n",
    "        spots = []\n",
    "        for j in range(len(matrix[0])):\n",
    "            if matrix[i][j] != 0 and not np.isnan(matrix[i][j]):\n",
    "                if matrix[i][j] < last:\n",
    "                    spots.append(j)\n",
    "                last = matrix[i][j]\n",
    "        \n",
    "        if len(spots) != 0:\n",
    "            non_inc[i] = spots\n",
    "        \n",
    "    if printy == True:\n",
    "        print(str(len(non_inc)) + \" schools are non increasing in at least one spot\")\n",
    "    return non_inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 schools are non increasing in at least one spot\n",
      "rank 26\n"
     ]
    }
   ],
   "source": [
    "is_inc(arr)\n",
    "print('rank ' + str(np.linalg.matrix_rank(arr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run through lmafit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the arrays needed for lmafit\n",
    "\n",
    "known_seq = [[],[]]\n",
    "known_values = []\n",
    "for i in range(len(arr)):\n",
    "    for j in range(len(arr[0])):\n",
    "        if arr[i][j] != 0:\n",
    "            known_seq[0].append(i)\n",
    "            known_seq[1].append(j)\n",
    "            known_values.append(arr[i][j])\n",
    "\n",
    "known_indices = [tuple(known_seq[0]), tuple(known_seq[1])]\n",
    "known_values = [tuple(known_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kq146\\code\\covid_college_tracker\\Covid_data\\src\\lmafit.py:39: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  Z[Known] = data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0            1            2      3           4           5     \\\n",
      "0    1841.000000  2020.000000  1755.000000  140.0  128.000000   73.000000   \n",
      "1    1888.000000  2020.000000  1755.000000  142.0  128.000000   92.000000   \n",
      "2    1922.000000  2020.000000  1831.000000  170.0  128.000000   92.000000   \n",
      "3    1957.000000  2020.000000  1831.000000  175.0  147.000000   92.000000   \n",
      "4    1967.000000  2020.000000  1868.000000  175.0  147.000000   92.000000   \n",
      "..           ...          ...          ...    ...         ...         ...   \n",
      "99   4501.000000     0.011228  3126.000000  844.0    0.063951  511.000000   \n",
      "100  4512.000000    -0.013741     0.105343  847.0   -0.075093   -0.469003   \n",
      "101  4518.000000     0.011024    -0.084586  873.0    0.060443    0.376767   \n",
      "102  4526.000000    -0.002896     0.022571  878.0   -0.017054   -0.101258   \n",
      "103    -0.055109    -0.007511     0.058205  886.0   -0.043226   -0.260374   \n",
      "\n",
      "            6            7            8           9     ...      1488  \\\n",
      "0    1888.000000  1053.000000   647.000000   433.00000  ...  0.006692   \n",
      "1    2044.000000  1053.000000   937.000000   433.00000  ... -0.017155   \n",
      "2    2159.000000  1053.000000  1156.000000   433.00000  ...  0.079776   \n",
      "3    2264.000000  1691.000000  1223.000000   433.00000  ... -0.057351   \n",
      "4    2304.000000  1691.000000  1299.000000   433.00000  ... -0.016003   \n",
      "..           ...          ...          ...         ...  ...       ...   \n",
      "99      0.067675  5125.000000  3867.000000  3233.00000  ...  0.003219   \n",
      "100    -0.082016  5125.000000  3874.000000  3233.00000  ... -0.005626   \n",
      "101     0.065825     0.018992  3882.000000  3233.00000  ...  0.004759   \n",
      "102    -0.017492    -0.004971  3891.000000  3233.00000  ... -0.002446   \n",
      "103    -0.045247    -0.012920     0.069049    -0.00497  ... -0.010053   \n",
      "\n",
      "         1489      1490      1491      1492      1493      1494       1495  \\\n",
      "0    0.207437  0.695918  0.602237  0.013383  0.006692  0.100373   4.797820   \n",
      "1   -0.531799 -1.784100 -1.543933 -0.034310 -0.017155 -0.257322 -12.299998   \n",
      "2    2.473062  8.296726  7.179859  0.159552  0.079776  1.196643  57.199542   \n",
      "3   -1.777876 -5.964488 -5.161576 -0.114702 -0.057351 -0.860263 -41.120554   \n",
      "4   -0.496101 -1.664337 -1.440292 -0.032006 -0.016003 -0.240049 -11.474326   \n",
      "..        ...       ...       ...       ...       ...       ...        ...   \n",
      "99   0.099778  0.334739  0.289678  0.006437  0.003219  0.048280   2.307768   \n",
      "100 -0.174419 -0.585148 -0.506378 -0.011253 -0.005626 -0.084396  -4.034142   \n",
      "101  0.147535  0.494958  0.428329  0.009518  0.004759  0.071388   3.412351   \n",
      "102 -0.075820 -0.254365 -0.220124 -0.004892 -0.002446 -0.036687  -1.753654   \n",
      "103 -0.311647 -1.045526 -0.904782 -0.020106 -0.010053 -0.150797  -7.208099   \n",
      "\n",
      "         1496      1497  \n",
      "0    0.006692  0.194054  \n",
      "1   -0.017155 -0.497489  \n",
      "2    0.079776  2.313510  \n",
      "3   -0.057351 -1.663174  \n",
      "4   -0.016003 -0.464094  \n",
      "..        ...       ...  \n",
      "99   0.003219  0.093341  \n",
      "100 -0.005626 -0.163166  \n",
      "101  0.004759  0.138017  \n",
      "102 -0.002446 -0.070929  \n",
      "103 -0.010053 -0.291541  \n",
      "\n",
      "[104 rows x 1498 columns]\n"
     ]
    }
   ],
   "source": [
    "X,Y,out = lmafit_mc_adp(len(arr),len(arr[0]),26,known_indices,known_values)\n",
    "\n",
    "complete = np.dot(X,Y)\n",
    "print(pd.DataFrame(complete).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for column increasing and do isotonic regression if not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1498 schools are non increasing in at least one spot\n"
     ]
    }
   ],
   "source": [
    "non_inc = is_inc(complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iso(matrix):\n",
    "    # performs isotonic regression for every school\n",
    "    tonic = copy.deepcopy(matrix) # returns a new isotonic matrix\n",
    "    \n",
    "    # dat dict tells me where things arent increasing\n",
    "    dat_dict = is_inc(matrix, False)\n",
    "    \n",
    "    for i in dat_dict.keys():\n",
    "        to_predict = dat_dict[i]\n",
    "        leng = len(tonic[0]) - len(to_predict)\n",
    "        initial_vals = list(tonic[i].copy())\n",
    "        X = list(range(len(tonic[i])))\n",
    "\n",
    "        # Use the increasing values to fit the model and then predict what the decreasing ones should be \n",
    "        iso = IsotonicRegression().fit(X,initial_vals)\n",
    "        predictions = iso.predict(range(len(tonic[i])))\n",
    "        \n",
    "        # put everything back:\n",
    "        tonic[i] = predictions\n",
    "    \n",
    "    return(tonic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_result = iso(complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 schools are non increasing in at least one spot\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_inc(iso_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0            1            2      3           4           5     \\\n",
      "0    1841.000000  2020.000000  1755.000000  140.0  128.000000   73.000000   \n",
      "1    1888.000000  2020.000000  1755.000000  142.0  128.000000   92.000000   \n",
      "2    1922.000000  2020.000000  1831.000000  170.0  128.000000   92.000000   \n",
      "3    1957.000000  2020.000000  1831.000000  175.0  147.000000   92.000000   \n",
      "4    1967.000000  2020.000000  1868.000000  175.0  147.000000   92.000000   \n",
      "..           ...          ...          ...    ...         ...         ...   \n",
      "99   4185.330709  3458.714083  2675.002603  844.0  724.683927  417.805219   \n",
      "100  4185.330709  3458.714083  2675.002603  847.0  724.683927  417.805219   \n",
      "101  4185.330709  3458.714083  2675.002603  873.0  724.683927  417.805219   \n",
      "102  4185.330709  3458.714083  2675.002603  878.0  724.683927  417.805219   \n",
      "103  4185.330709  3458.714083  2675.002603  886.0  724.683927  417.805219   \n",
      "\n",
      "            6            7            8            9     ...      1488  \\\n",
      "0    1888.000000  1053.000000   647.000000   433.000000  ... -0.009282   \n",
      "1    2044.000000  1053.000000   937.000000   433.000000  ... -0.009282   \n",
      "2    2159.000000  1053.000000  1156.000000   433.000000  ... -0.009282   \n",
      "3    2264.000000  1691.000000  1223.000000   433.000000  ... -0.009282   \n",
      "4    2304.000000  1691.000000  1299.000000   433.000000  ... -0.009282   \n",
      "..           ...          ...          ...          ...  ...       ...   \n",
      "99   4344.972956  4594.210555  3636.669224  3006.499774  ...  0.110256   \n",
      "100  4344.972956  4594.210555  3636.669224  3006.499774  ...  0.110256   \n",
      "101  4344.972956  4594.210555  3636.669224  3006.499774  ...  0.110256   \n",
      "102  4344.972956  4594.210555  3636.669224  3006.499774  ...  0.110256   \n",
      "103  4344.972956  4594.210555  3636.669224  3006.499774  ...  0.110256   \n",
      "\n",
      "         1489       1490      1491      1492      1493      1494       1495  \\\n",
      "0   -0.287754  -0.965368 -0.835414 -0.018565 -0.009282 -0.139236  -6.655469   \n",
      "1   -0.287754  -0.965368 -0.835414 -0.018565 -0.009282 -0.139236  -6.655469   \n",
      "2   -0.287754  -0.965368 -0.835414 -0.018565 -0.009282 -0.139236  -6.655469   \n",
      "3   -0.287754  -0.965368 -0.835414 -0.018565 -0.009282 -0.139236  -6.655469   \n",
      "4   -0.287754  -0.965368 -0.835414 -0.018565 -0.009282 -0.139236  -6.655469   \n",
      "..        ...        ...       ...       ...       ...       ...        ...   \n",
      "99   3.417941  11.466640  9.923054  0.220512  0.110256  1.653842  79.053662   \n",
      "100  3.417941  11.466640  9.923054  0.220512  0.110256  1.653842  79.053662   \n",
      "101  3.417941  11.466640  9.923054  0.220512  0.110256  1.653842  79.053662   \n",
      "102  3.417941  11.466640  9.923054  0.220512  0.110256  1.653842  79.053662   \n",
      "103  3.417941  11.466640  9.923054  0.220512  0.110256  1.653842  79.053662   \n",
      "\n",
      "         1496      1497  \n",
      "0   -0.009282 -0.269189  \n",
      "1   -0.009282 -0.269189  \n",
      "2   -0.009282 -0.269189  \n",
      "3   -0.009282 -0.269189  \n",
      "4   -0.009282 -0.269189  \n",
      "..        ...       ...  \n",
      "99   0.110256  3.197428  \n",
      "100  0.110256  3.197428  \n",
      "101  0.110256  3.197428  \n",
      "102  0.110256  3.197428  \n",
      "103  0.110256  3.197428  \n",
      "\n",
      "[104 rows x 1498 columns]\n"
     ]
    }
   ],
   "source": [
    "fin = pd.DataFrame(iso_result)\n",
    "#fin.index = incomplete_matr.columns\n",
    "print(fin.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
